REVIEW THIS QWIKLABS COURSE FOR AN IN-DEPTH KNOWLEDGE ON KUBERNETES AND GKE: https://googlecourses.qwiklabs.com/course_templates/34
--------------------------------------------------------------------------------------------------
Controllers:
https://kubernetes.io/docs/concepts/architecture/controller/
In Kubernetes, controllers are control loops that watch the state of your cluster, then make or request changes where needed. Each controller tries to move the current cluster state closer to the desired state.
Kubernetes comes with a set of built-in controllers that run inside the kube-controller-manager. These built-in controllers provide important core behaviors.
The Deployment controller and Job controller are examples of controllers that come as part of Kubernetes itself ("built-in" controllers).
-------------------------------------------------------------------------------------------------
ReplicaSet:
https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/
A ReplicaSet's purpose is to maintain a stable set of replica Pods running at any given time. Usually, you define a Deployment and let that Deployment manage ReplicaSets automatically.
A ReplicaSet ensures that a specified number of pod replicas are running at any given time. However, a Deployment is a higher-level concept that manages ReplicaSets and provides declarative updates to Pods along with a lot of other useful features.

Check chatgpt "ReplicaSet vs Deployment"
-------------------------------------------------------------------------------------------------
Horizontal Pod Autoscaler:
https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
In Kubernetes, a HorizontalPodAutoscaler automatically updates a workload resource (such as a Deployment or StatefulSet), with the aim of automatically scaling the workload to match demand.
If the load decreases, and the number of Pods is above the configured minimum, the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet, or other similar resource) to scale back down.
The horizontal pod autoscaling controller, running within the Kubernetes control plane, periodically adjusts the desired scale of its target (for example, a Deployment) to match observed metrics such as average CPU utilization, average memory utilization, or any other custom metric you specify.
Kubernetes implements horizontal pod autoscaling as a control loop that runs intermittently (it is not a continuous process).

-------------------------------------------------------------------------------------------------
Horizontal Pod Autoscaler Example:
https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/

Create an autoscaler for a deployment called php-apache, with a target CPU utilization of 50 percent, a minimum of 1 pod, and a maximum of 10 pods:
kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10

The yaml definition of the HorizontalPodAutoscaler created would look like this:
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: php-apache
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: php-apache
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
---
You can check the current status of the newly-made HorizontalPodAutoscaler, by running:
kubectl get hpa
-------------------------------------------------------------------------------------------------
Deployment:
https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
Kubernetes deployments are used to manage stateless applications.
While updating a deployment, if the image tag is not changed, Kubernetes will not pull the new image by default. To force Kubernetes to pull the new image, you can set the imagePullPolicy to Always in the deployment manifest.

Rollout a Deployment:
A Deployment's rollout is triggered if and only if the Deployment's Pod template (that is, .spec.template) is changed, for example if the labels or container images of the template are updated. Other updates, such as scaling the Deployment, do not trigger a rollout.

Rollback a Deployment:
Sometimes, you may want to rollback a Deployment; for example, when the Deployment is not stable, such as crash looping. By default, all of the Deployment's rollout history is kept in the system so that you can rollback anytime you want (you can change that by modifying revision history limit).
A Deployment's revision is created when a Deployment's rollout is triggered. This means that the new revision is created if and only if the Deployment's Pod template (.spec.template) is changed.
kubectl rollout undo deployment/nginx-deployment
kubectl rollout undo deployment/nginx-deployment --to-revision=2

Rolling update strategy:
By default, a Deployment uses the RollingUpdate strategy to replace old Pods with new ones. This strategy ensures that some Pods are always available during the update process.
You can customize the rolling update behavior by specifying the maxUnavailable and maxSurge parameters in the rollingUpdate section of the Deployment spec.
Advantage: No downtime during the update process.
Disadvantage: Some users may still be accessing the old version of the application while others are accessing the new version.

Recreate strategy:
All existing Pods are killed before new ones are created when .spec.strategy.type==Recreate.
Advantage: All users will gain access to the new version of the application at the same time.
Disadvantage: There will be a downtime during the update process.

Blue-Green Deployment:
Blue-green deployments are a deployment strategy that reduces downtime and risk by running two identical production environments.
Blue environment: the live environment that serves all production traffic.
Green environment: the idle environment where the new version of the application is deployed and tested.
Once the green environment is verified to be working correctly, the traffic is switched from the blue environment to the green environment.
Advantage: Minimal downtime during the switch.
Disadvantage: Requires double the resources during the deployment process.

Canary Deployment:
Canary deployments are a deployment strategy that releases an application to a small subset of users before rolling it out to the entire infrastructure and user base.
Kubernetes does not have built-in support for canary deployments, but you can implement them using a combination of Deployments, Services, and labels.
https://kubernetes.io/docs/concepts/workloads/management/#canary-deployments
Advantage: Allows for testing the new version with a small group of users before a full rollout.
Disadvantage: It is slower and may require additional tooling, such as service mesh, to manage traffic routing.

---
apiVersion: apps/v1
kind: Deployment
metadata:
 name: nginx-deployment
 labels:
   app: nginx
spec:
 replicas: 3
 selector:
   matchLabels:
     app: nginx
 template:
   metadata:
     labels:
       app: nginx
   spec:
     containers:
     - name: nginx
       image: nginx:1.14.2
       ports:
       - containerPort: 80
 strategy:
   type: RollingUpdate
   rollingUpdate:
     maxSurge: 1
     maxUnavailable: 1
---
-------------------------------------------------------------------------------------------------
Pod requests and limits:
https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
Requests: Minimum amount of CPU or memory that a container requires. The scheduler uses this information to decide on which node to place the Pod. If you specify a CPU or memory value that is larger than the node's available resources, the Pod will not be scheduled.
Limits: Sets the upper bound on the amount of CPU or memory that a container can use. Prevents a container from consuming too many resources and affecting other containers on the same node.
Kube-scheduler uses requests to schedule pods onto nodes, while the kubelet enforces limits at runtime.