Cheat Sheet
https://cloud.google.com/sdk/gcloud/reference/cheat-sheet
-------------------------------------
To enable gcloud interactive mode:
gcloud beta interactive

When using the interactive mode, press TAB to complete file path and resource arguments. If a dropdown menu appears, press TAB to move through the list, and press the spacebar to select your choice.
When using the interactive mode, press TAB to complete file path and resource arguments. If a dropdown menu appears, press TAB to move through the list, and press the spacebar to select your choice.
gcloud compute instances describe <your_vm>

To install a component using gcloud. For example to install the cbt(bigtable) component:
gcloud components update
gcloud components install cbt

---------------------------------------
Compute engine default config:

To View the list of configurations in your environment:
gcloud config list

To list all the properties:
gcloud config list --all

To list the default zone of compute in the config of your env:
gcloud config list compute/zone

To set your default compute zone to us-central1-a:
gcloud config set compute/zone us-central1-a

To see what your default region and zone settings are:
gcloud config get-value compute/zone
gcloud config get-value compute/region

To list the default configuration(for compute engine) of a GCP project:
gcloud compute project-info describe --project <your_project_ID>

To get all the gcloud commands:
gcloud -h OR gcloud --help

--------------------------------------
Compute Engine VM instance:

To create VM instance:
gcloud compute instances create privatenet-us-vm --zone=us-central1-c --machine-type=f1-micro --subnet=privatesubnet-us --image-family=debian-10 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-standard --boot-disk-device-name=privatenet-us-vm

To list all the VM instances (sorted by zone):
gcloud compute instances list --sort-by=ZONE

SSH to a VM instance:
gcloud compute ssh vm-internal --zone us-central1-c

SSH to a private VM instance using IAP tunnel:
gcloud compute ssh vm-internal --zone us-central1-c --tunnel-through-iap

Move a VM instance from one zone to another:
gcloud compute instances move example-instance-1  --zone us-central1-b --destination-zone us-central1-f

To create target pools:
gcloud compute target-pools create www-pool --region us-central1 --http-health-check basic-check
Target pool-based load balancers can only use legacy HTTP health checks.

To add instances in the target pool:
gcloud compute target-pools add-instances www-pool --instances www1,www2,www3

To create compute instance group from template:
gcloud compute instance-groups managed create lb-backend-group --template=lb-backend-template --size=2 --zone=us-central1-a

To create a disk:
gcloud compute disks create [DISK_NAME] \
  --size [DISK_SIZE] \
  --type [DISK_TYPE]

To create a regional persistent disk:
gcloud compute disks create DISK_NAME \
    --size=DISK_SIZE \
    --type=DISK_TYPE \
    --region=REGION \
    --replica-zones=ZONE1,ZONE2

To attach the regional disk to a vm instance:
gcloud compute instances attach-disk INSTANCE_NAME \
    --disk=DISK_NAME \
    --disk-scope=regional

To attach a disk to an instance:
gcloud compute instances attach-disk [INSTANCE_NAME] \
  --disk [DISK_NAME]

To resize a disk:
gcloud compute disks resize [DISK_NAME] --size [DISK_SIZE]

To creating a snapshot of a zonal persistent disk:
gcloud compute disks snapshot [DISK_NAME] --storage-location [STORAGE_LOCATION]

To creating a snapshot of a regional persistent disk:
gcloud compute disks snapshot [DISK_NAME] --region [REGION] --storage-location [STORAGE_LOCATION]

To create a disk from a snapshot:
gcloud compute disks create DISK_NAME \
    --size=DISK_SIZE \
    --source-snapshot=SNAPSHOT_NAME \
    --type=DISK_TYPE

To create a snapshot schedule:
  gcloud compute resource-policies create snapshot-schedule [SCHEDULE_NAME] \
      --description "[SCHEDULE_DESCRIPTION]" \
      --max-retention-days [MAX_RETENTION_DAYS] \
      --start-time [START_TIME] \
      --hourly-schedule [SNAPSHOT_INTERVAL] \
      --daily-schedule \
      --weekly-schedule [SNAPSHOT_INTERVAL] \
      --weekly-schedule-from-file [FILE_NAME] \
      --on-source-disk-delete [DELETION_OPTION]

To attach a snapshot schedule to a disk:
gcloud compute disks add-resource-policies [DISK_NAME] \
    --resource-policies [SCHEDULE_NAME] \
    --zone [ZONE]

To view snapshot schedules:
gcloud compute resource-policies list

To setting the auto-delete state of a zonal persistent disk:
gcloud compute instances set-disk-auto-delete example-instance \
  [--auto-delete|--no-auto-delete] \
  --disk DISK_NAME

-------------------------------------------------------------------------
VPC Network:

To create a VPC network(custom mode):
gcloud compute networks create privatenet --subnet-mode=custom

To create subnet in a VPC network(say the VPC network name is "privatenet"):
gcloud compute networks subnets create privatesubnet-us --network=privatenet --region=us-central1 --range=172.16.0.0/24

To list VPC networks:
gcloud compute networks list

To list the available VPC subnets (sorted by VPC network):
gcloud compute networks subnets list --sort-by=NETWORK

To enable vpc flow logs in a subnet:
gcloud compute networks subnets create SUBNET_NAME \
    --enable-flow-logs \
    [other flags as needed]

To enable vpc flow logs for existing subnets:
gcloud compute networks subnets update SUBNET_NAME \
    --enable-flow-logs \
    [other flags as needed]

To create a firewall rule:
gcloud compute firewall-rules create privatenet-allow-icmp-ssh-rdp --direction=INGRESS --priority=1000 --network=privatenet --action=ALLOW --rules=icmp,tcp:22,tcp:3389 --source-ranges=0.0.0.0/0

To list all the firewall rules (sorted by VPC network):
gcloud compute firewall-rules list --sort-by=NETWORK

To enable firewall logging:
gcloud compute firewall-rules update NAME \
    --enable-logging
    --logging-metadata=LOGGING_METADATA

To disable firewall logging:
gcloud compute firewall-rules update NAME \
    --no-enable-logging

To create a regional static external IP address:
gcloud compute addresses create network-lb-ip-1 --region us-central1

To create a global static external IP address:
gcloud compute addresses create lb-ipv4-1 --ip-version=IPV4 --global

To create firewall rule for health check rule for global http(s) load balancer. This is an ingress rule that allows traffic from the Google Cloud health checking systems (130.211.0.0/22 and 35.191.0.0/16).
gcloud compute firewall-rules create fw-allow-health-check \
    --network=default \
    --action=allow \
    --direction=ingress \
    --source-ranges=130.211.0.0/22,35.191.0.0/16 \
    --target-tags=allow-health-check \
    --rules=tcp:80

To create health check:
gcloud compute health-checks create http http-basic-check --port 80

-------------------------------------------------------------------------
Google Cloud Storage:

To create a bucket:
gsutil mb gs://BUCKET_NAME
OR
gsutil mb -p [PROJECT_ID] -c [STORAGE_CLASS] -l [BUCKET_LOCATION] -b on gs://BUCKET_NAME
WHERE -p: Specify the project with which your bucket will be associated. For example, my-project.
      -c: Specify the default storage class of your bucket. For example, NEARLINE.
      -l: Specify the location of your bucket. For example, US-EAST1.
      -b: Enable uniform bucket-level access for your bucket.

To list items in a bucket:
gsutil ls gs://[YOUR_BUCKET_NAME]

To upload a file in a bucket:
gsutil cp setup.html gs://$BUCKET_NAME_1

To get the acl list for an object in a bucket:
gsutil acl get gs://$BUCKET_NAME_1/setup.html  > acl.txt

To set the access list to private:
gsutil acl set private gs://$BUCKET_NAME_1/setup.html

To update the access list to make the file publicly readable:
gsutil acl ch -u AllUsers:R gs://$BUCKET_NAME_1/setup.html

To make all objects in a bucket readable to everyone on the public internet (For uniform bucket level access enabled bucket):
gsutil iam ch allUsers:objectViewer gs://BUCKET_NAME

To view the current lifecycle policy of a bucket:
gsutil lifecycle get gs://$BUCKET_NAME_1

To set the lifecycle policy of a bucket(using json):
gsutil lifecycle set life.json gs://$BUCKET_NAME_1

To view the current versioning status for the bucket:
gsutil versioning get gs://$BUCKET_NAME_1

To enable versioning of a bucket:
gsutil versioning set on gs://$BUCKET_NAME_1

To copy a file to the bucket with the versioning:
gsutil cp -v setup.html gs://$BUCKET_NAME_1

To list all versions of the file:
gsutil ls -a gs://$BUCKET_NAME_1/setup.html

To download noncurrent version of an object:
gsutil cp gs://[SOURCE_BUCKET_NAME]/[SOURCE_OBJECT_NAME#GENERATION_NUMBER] gs://[DESTINATION_BUCKET_NAME]/[DESTINATION_OBJECT_NAME]
WHERE "GENERATION_NUMBER" is the generation number for the noncurrent version you want to copy. For example,1560468815691234.

To delete noncurrent version of an object:
gsutil rm gs://[BUCKET_NAME]/[OBJECT_NAME#GENERATION_NUMBER]

To sync a local folder with cloud storage bucket:
gsutil rsync -r ./firstlevel gs://$BUCKET_NAME_1/firstlevel
(Where firstlevel is the local folder, whose contents will be copied into the bucket recursively)

To change the storage class of object:
gsutil rewrite -s STORAGE_CLASS gs://PATH_TO_OBJECT

To change the default storage class of a bucket:
gsutil defstorageclass set STORAGE_CLASS gs://BUCKET_NAME

To enable uniform bucket level access(which disables object level ACLs):
gsutil uniformbucketlevelaccess set on gs://BUCKET_NAME

To get uniform bucket level access status:
gsutil uniformbucketlevelaccess get gs://BUCKET_NAME

To disable uniform bucket level access:
gsutil uniformbucketlevelaccess set off gs://BUCKET_NAME

To get the size of a bucket:
gsutil du -s gs://BUCKET_NAME

To get metadata of a bucket:
gsutil ls -L -b gs://BUCKET_NAME

To get metadata of an object:
gsutil stat gs://BUCKET_NAME/OBJECT_NAME

To delete a bucket:
gsutil rm -r gs://BUCKET_NAME

To apply notification configuration in your bucket:
gsutil notification create -t TOPIC_NAME -f json gs://BUCKET_NAME
If you use a TOPIC_NAME that doesn't exist in your project, gsutil creates one for you.

To list notification configuration of a bucket:
gsutil notification list gs://BUCKET_NAME

-------------------------------------------------------------------

Hybrid Connectivity:

Cloud VPN facilitates the connection of GCP resources present in a particular VPC network with other networks (either VPC network or external network), using a secured tunnel and internal IP addresses.

Dedicated and Partner Interconnect also facilitates the connection of on-premise resource with GCP resources using internal IP addresses.

Direct and Carrier peering facilitates the connection of on-premise resources with GCP resources using Google's edge point of presence (PoP) using public IP address.

See: https://callcenterstudio.com/google-cloud-connection-blogs/

Shared VPC and VPC peering is a way to establish direct connection between resources residing on seperate VPC networks using internal IP address. Cloud VPN is another way to achieve the same, but Shared VPC/VPC peering is more suitable for this type of scenario and comes with low network latency and low cost.

-------------------------------------------------------------------
Understanding the difference between TCP and HTTP:

https://stackoverflow.com/questions/23157817/http-vs-tcp-ip-send-data-to-a-web-server

Understanding forwarding rule in GCP:
https://cloud.google.com/load-balancing/docs/forwarding-rule-concepts

-------------------------------------------------------------------
Deployment Manager:

To create a deployment. The --preview flag gives a preview without actually starting the deployment.
gcloud deployment-manager deployments create dminfra --config=config.yaml --preview

To actually start a deployment which has been created using the command as shown above, use the below command. The update command commits the preview.
gcloud deployment-manager deployments update dminfra

To create and start the deployment at the same time, without previewing it, run the command.
gcloud deployment-manager deployments create dminfra --config=config.yaml

To delete a deployment.
gcloud deployment-manager deployments delete dminfra

-------------------------------------------------------------------
Google Kubernetes Engine:

To create a kubernetes cluster:
gcloud container clusters create [CLUSTER-NAME]

To create multi zonal cluster with autoscaling enabled:
gcloud container clusters create [CLUSTER-NAME] \
  --num-nodes 2 \
  --zone us-central1-a \
  --node-locations us-central1-a,us-central1-b,us-central1-f \
  --enable-autoscaling --min-nodes 1 --max-nodes 4

This will create six nodes across three zones initially, with a minimum of one node per zone and a maximum of four nodes per zone.
In this example, the total size of the cluster can be between three and twelve nodes, spread across the three zones.
If one of the zones fails, the total size of the cluster can be between two and eight nodes.

To create a regional cluster:
gcloud container clusters create CLUSTER_NAME \
    --cluster-version VERSION
    --region COMPUTE_REGION

SEE: https://cloud.google.com/kubernetes-engine/docs/concepts/types-of-clusters
     https://cloud.google.com/kubernetes-engine/docs/how-to/creating-a-regional-cluster
A multi-zonal cluster has a single replica of the control plane running in a single zone, and has nodes running in multiple zones.
A regional cluster has multiple replicas of the control plane, running in multiple zones within a given region.

To enable autoscaling for an existing node pool, run the following command:
gcloud container clusters update [cluster-name] --enable-autoscaling \
    --min-nodes 1 --max-nodes 10 --region [compute-region] || --zone [compute-zone] --node-pool default-pool

To disable autoscaling for a specific node pool, run the following command:
gcloud container clusters update [cluster-name] --no-enable-autoscaling \
    --node-pool pool-name [--zone compute-zone --project project-id]

To authenticate the cluster:
gcloud container clusters get-credentials [CLUSTER-NAME]

To create a deployment (deploy a containerized application):
kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0

To create a deployment using a deployment descriptor (Pod template):
kubectl apply -f [DEPLOYMENT_DESCRIPTOR]

To create a Kubernetes Service, which is a Kubernetes resource that lets you expose your application to external traffic:
kubectl expose deployment hello-server --type=LoadBalancer --port 8080

To get the list of pods (filtered by key-value pair):
kubectl get pods -l [KEY=VALUE]

To get information about a specific Pod:
kubectl describe pod [POD_NAME]

To view a Deployment's manifest, run the following command:
kubectl get deployments [DEPLOYMENT_NAME] -o yaml

To get the list of kubernetes services:
kubectl get service

To update a deployment, with new version of app:
kubectl apply -f [DEPLOYMENT_FILE]
or
kubectl set image deployment nginx nginx=nginx:1.9.1
See: https://cloud.google.com/kubernetes-engine/docs/how-to/stateless-apps#update

To roll back an update:
kubectl rollout undo deployment my-deployment
or to rollback to specific version
kubectl rollout undo deployment my-deployment --to-revision=3

To scale a deployment (other than auto-scaling):
kubectl scale deployment [DEPLOYMENT_NAME] --replicas [NUMBER_OF_REPLICAS]

Tp apply autoscaling for a deployment:
kubectl autoscale deployment my-app --max 6 --min 4 --cpu-percent 50

To delete a cluster:
gcloud container clusters delete [CLUSTER-NAME]

To get details of deployment:
kubectl describe deployments

To disable cloud operations for GKE (cloud monitoring and logging),while creating a cluster:
gcloud container clusters create [CLUSTER_NAME] \
  --zone=[ZONE] \
  --project=[PROJECT_ID] \
  --cluster-version=[CLUSTER_VERSION] \
  --no-enable-stackdriver-kubernetes
Otherwise cloud Operations for GKE is enabled by default.

To enable Cloud Operations for GKE, in an existing cluster:
gcloud container clusters update [CLUSTER_NAME] \
  --zone=[ZONE]  \
  --enable-stackdriver-kubernetes

--------------------------------------------------------------------
How to create managed load-balanced instance group:

1. First, create the instance template:

gcloud compute instance-templates create lb-backend-template \
   --region=us-central1 \
   --network=default \
   --subnet=default \
   --tags=allow-health-check \
   --image-family=debian-9 \
   --image-project=debian-cloud \
   --metadata=startup-script='#! /bin/bash
     apt-get update
     apt-get install apache2 -y
     a2ensite default-ssl
     a2enmod ssl
     vm_hostname="$(curl -H "Metadata-Flavor:Google" \
     http://169.254.169.254/computeMetadata/v1/instance/name)"
     echo "Page served from: $vm_hostname" | \
     tee /var/www/html/index.html
     systemctl restart apache2'

2. Create a managed instance group based on the template:

gcloud compute instance-groups managed create lb-backend-group \
   --template=lb-backend-template --size=2 --zone=us-central1-a

3. Create the "fw-allow-health-check" firewall rule. This is an ingress rule that allows traffic from the Google Cloud health checking systems (130.211.0.0/22 and 35.191.0.0/16).
This lab uses the target tag allow-health-check to identify the VMs.

gcloud compute firewall-rules create fw-allow-health-check \
    --network=default \
    --action=allow \
    --direction=ingress \
    --source-ranges=130.211.0.0/22,35.191.0.0/16 \
    --target-tags=allow-health-check \
    --rules=tcp:80

4. Now that the instances are up and running, set up a global static external IP address that your customers use to reach your load balancer.

gcloud compute addresses create lb-ipv4-1 \
    --ip-version=IPV4 \
    --global

5. Note the IPv4 address that was reserved:

gcloud compute addresses describe lb-ipv4-1 \
    --format="get(address)" \
    --global

6. Create a healthcheck for the load balancer:

    gcloud compute health-checks create http http-basic-check \
        --port 80

7. Create a backend service (Each backend service is associated with an instance group):

    gcloud compute backend-services create web-backend-service \
        --protocol=HTTP \
        --port-name=http \
        --health-checks=http-basic-check \
        --global
8. Add your instance group as the backend to the backend service:

    gcloud compute backend-services add-backend web-backend-service \
        --instance-group=lb-backend-group \
        --instance-group-zone=us-central1-a \
        --global

9. Create a URL map to route the incoming requests to the default backend service:

    gcloud compute url-maps create web-map-http \
        --default-service web-backend-service

10. Create a target HTTP proxy to route requests to your URL map:

    gcloud compute target-http-proxies create http-lb-proxy \
        --url-map web-map-http

11. Create a global forwarding rule to route incoming requests to the proxy (Consider the forwarding rule as load balancer):

    gcloud compute forwarding-rules create http-content-rule \
        --address=lb-ipv4-1\
        --global \
        --target-http-proxy=http-lb-proxy \
        --ports=80

-------------------------------------------------------------------------------------------
Cloud SQL:

TO create a mysql instance:
gcloud sql instances create [INSTANCE_NAME] --cpu=[NUMBER_CPUS] --memory=[MEMORY_SIZE] --region=[REGION]
OR
gcloud sql instances create [INSTANCE_NAME] --tier=[API_TIER_STRING] --region=[REGION]
For example, the following string creates an instance with two vCPUs and 7,680 MB of memory:
gcloud sql instances create myinstance --database-version=MYSQL_8_0 --cpu=2 --memory=7680MB --region=us-central1

To set the password for the "root@%" MySQL user:
gcloud sql users set-password root --host=% --instance INSTANCE_NAME --password PASSWORD

To connect to a cloud sql instance:
gcloud sql connect [INSTANCE_NAME]] --user=root

To view summary information about your Cloud SQL instances:
gcloud sql instances describe [INSTANCE_NAME]

To edit an instance:
gcloud sql instances patch [INSTANCE_NAME] --backup-start-time 16:00

To clone an instance:
gcloud sql instances clone [SOURCE_INSTANCE_NAME] [TARGET_INSTANCE_NAME]

To start a stopped instance:
gcloud sql instances patch [INSTANCE_NAME] --activation-policy ALWAYS

Activation policy options are:
ALWAYS - The instance is always up and running.
NEVER- The instance is not restarted.
If you are using a MySQL instance, you generally set your activation policy to ALWAYS to accept connection requests.
If you are not using your instance, you can set its activation policy to NEVER to avoid instance charges.

To stop an instance:
gcloud sql instances patch [INSTANCE_NAME] --activation-policy NEVER

To restart an instance:
gcloud sql instances restart [INSTANCE_NAME]

To delete an instance:
gcloud sql instances delete [INSTANCE_NAME]

To filter instance searches using labels:
gcloud beta sql instances list --filter='labels.billing-code:34802'

To add an IPv4 address (public ip) to the instance:
gcloud sql instances patch [INSTANCE_NAME] --assign-ip

TO show all existing authorized addresses by describing the instance:
gcloud sql instances describe [INSTANCE_NAME]

To update the authorized network list, including all addresses you want included:
gcloud sql instances patch [INSTANCE_NAME] --authorized-networks=[IP_ADDR1],[IP_ADDR2]...

To remove all authorized networks:
gcloud sql instances patch [INSTANCE_NAME] --clear-authorized-networks

To configure an instance to refuse all public IP connections, Clear the authorized address list:
gcloud sql instances patch [INSTANCE_NAME] --clear-authorized-networks

To disable public IP:
gcloud sql instances patch [INSTANCE_NAME] --no-assign-ip

To create sql instance with high availability:
gcloud sql instances create [REGIONAL_INSTANCE_NAME] \
                     --availability-type=REGIONAL \
                     --database-version=[DATABASE_VERSION] \
                     --tier=[MACHINE_TYPE] \
                     --enable-bin-log
You can specify both the primary and secondary zones, using the --zone and --secondary-zone parameters.
The following restrictions apply when the secondary zone is used during instance creation or edit:
1. The zones must be valid zones.
2. If the secondary zone is specified, the primary must also be specified.
3. If the primary and secondary zones are specified, they must be distinct zones.
4. If the primary and secondary zones are specified, they must belong to the same region.

To update an existing sql instance to be highly available:
gcloud sql instances patch [INSTANCE_NAME] --availability-type REGIONAL --enable-bin-log --backup-start-time=[HH:MM]

To initiate a failover:
gcloud sql instances failover [PRIMARY_INSTANCE_NAME]

To disable high availability:
gcloud sql instances patch [INSTANCE_NAME] --availability-type ZONAL

To create an on-demand backup:
gcloud sql backups create --async --instance [INSTANCE_NAME]

To schedule automated backups:
gcloud sql instances patch [INSTANCE_NAME] --backup-start-time [HH:MM]

To view backups of an instance:
gcloud sql backups list --instance [INSTANCE_NAME]

To list the details of one backup, use the ID from the output of the backups list command:
gcloud sql backups describe [BACKUP_ID] --instance [INSTANCE_NAME]

TO set the number of automated backups to retain:
gcloud sql instances patch [instance-name] --retained-backups-count num-to-retain

To disable automated backups:
gcloud sql instances patch [INSTANCE_NAME] --no-backup

To restore the same instance from a backup:
gcloud sql backups restore [BACKUP_ID] --restore-instance=[INSTANCE_NAME]

To enable point-in-time recovery:
gcloud sql instances patch [INSTANCE_NAME] --enable-bin-log

To disable point-in-time recovery:
gcloud sql instances patch [INSTANCE_NAME] --no-enable-bin-log

To create a read replica:
gcloud sql instances create [REPLICA_NAME] --master-instance-name=PRIMARY_INSTANCE_NAME
You can specify a different tier size using the --tier parameter, if needed.
You can specify a different region using the --region parameter.
If the primary instance has a private IP address only, add the --no-assign-ip parameter to the command.
You must create the replica in the same VPC network as the primary instance.

Note: A read replica can be in a different region whereas a failover instance should be in the same region as the primary instance,
but maybe in a different zone.

To promote a replica to a standalone instance:
gcloud sql instances promote-replica [REPLICA_NAME]

To import data from sql dump file (uploaded in cloud storage) into cloud sql:
gcloud sql import sql [INSTANCE_NAME] gs://[BUCKET_NAME]/[IMPORT_FILE_NAME] --database=[DATABASE_NAME]

To import data from csv file (uploaded in cloud storage) into cloud sql:
gcloud sql import csv [INSTANCE_NAME] gs://[BUCKET_NAME]/[FILE_NAME] --database=[DATABASE_NAME] --table=[TABLE_NAME]

To export data from cloud sql instance to a sqldump (stored in cloud storage):
gcloud sql export sql [INSTANCE_NAME] gs://[BUCKET_NAME]/sqldumpfile.gz \
                              --database=[DATABASE_NAME] --offload
Note: Use the --offload flag if you want to use serverless export. Otherwise, remove it from the following command.

To export data from cloud sql instance to a csv file (stored in cloud storage):
gcloud sql export csv [INSTANCE_NAME] gs://[BUCKET_NAME]/[FILE_NAME] \
                            --database=[DATABASE_NAME] \
                            --offload \
                            --query=[SELECT_QUERY]
The query is used to select the data to be exported in csv file.

To create a database in a cloud sql instance:
gcloud sql databases create [DATABASE_NAME] --instance=[INSTANCE_NAME]
[--charset=CHARSET] [--collation=COLLATION]

To list databases:
gcloud sql databases list --instance=[INSTANCE_NAME]

To delete a database:
gcloud sql databases delete [DATABASE_NAME] --instance=[INSTANCE_NAME]

To create a user:
gcloud sql users create [user_name] \
   --host=[HOST] --instance=[INSTANCE_NAME] --password=[PASSWORD]

To change a user password:
gcloud sql users set-password [USER_NAME] \
   --host=[HOST] --instance=[INSTANCE_NAME] --prompt-for-password
-------------------------------------------------------------------------------------------
IAM:

To grant the Viewer role to the user my-user@example.com for the project my-project:
gcloud projects add-iam-policy-binding my-project \
    --member=user:my-user@example.com --role=roles/viewer

To quickly revoke a role from a user:
gcloud projects remove-iam-policy-binding my-project \
    --member=user:my-user@example.com --role=roles/viewer

To get the all iam policies of a project:
gcloud projects get-iam-policy my-project --format json > ~/policy.json

To set the iam policies of a project:
gcloud projects set-iam-policy [project-id] [filepath]

To list grantable roles for a resource identified via full resource name (for example a compute engine instance):
gcloud iam list-grantable-roles  //compute.googleapis.com/projects/example-project/zones/us-central1-f/instances/example-instance

-------------------------------------------------------------------------------------------
BigTable:
To create a bigtable instance with a single cluster:
gcloud bigtable instances create INSTANCE_ID \
    --display-name=DISPLAY_NAME \
    [--cluster-config=id=CLUSTER_ID,zone=CLUSTER_ZONE,[nodes=CLUSTER_NUM_NODES,kms-key=KMS_KEY]] \
    [--cluster-storage-type=CLUSTER_STORAGE_TYPE]
INSTANCE_ID: The permanent identifier for the instance.
DISPLAY_NAME: A human-readable name that identifies the instance in the Cloud Console.
CLUSTER_ID: The permanent identifier for the cluster.
CLUSTER_ZONE: The zone where the cluster runs.
The command accepts the following optional flags:
--cluster-config=nodes=CLUSTER_NUM_NODES: The number of nodes in the cluster.
Each cluster in an instance must have 1 or more nodes. The default value is 1.
If you aren't sure how many nodes you need, use the default. You can add more nodes later. Learn more.
--cluster-config=kms-key=KMS_KEY: A CMEK key ID. Use this if you want the instance to be CMEK-protected. You cannot add this later. Learn more.
--cluster-storage-type=CLUSTER_STORAGE_TYPE: The type of storage to use for the cluster.
Each cluster in an instance must use the same storage type. Accepts the values SSD and HDD. The default value is SSD.

To enable replication for a production instance, create another cluster:
gcloud bigtable clusters create CLUSTER_ID \
    --instance=INSTANCE_ID \
    --zone=ZONE \
    [--num-nodes=NUM_NODES] \
    [--kms-key=KMS_KEY] \
    [--project=PROJECT]
See: https://cloud.google.com/bigtable/docs/creating-instance
ZONE: The zone where the cluster runs.
An instance's clusters must each be in unique zones.
You can create an additional cluster in any zone where Bigtable is available.
For example, if the first cluster is in us-east1-b, you can choose a different zone in the same region, such as us-east1-c,
or a zone in a separate region, such as europe-west2-a.

Common uses of labels:
We do not recommend creating large numbers of unique labels, such as for timestamps or individual values for every API call.
Here are some common use cases for labels:
1. Team or cost center labels: Add labels based on team or cost center to distinguish instances owned by different teams (for example, team:research and team:analytics). You can use this type of label for cost accounting or budgeting.
2. Component labels: For example, component:redis, component:frontend, component:ingest, and component:dashboard.
3. Environment or stage labels: For example, environment:production and environment:test.
4. State labels: For example, state:active, state:readytodelete, and state:archive.

To list bigtable instances:
gcloud bigtable instances list
OR
cbt listinstances

To list the clusters in a particular instance:
gcloud bigtable clusters list --instances=INSTANCE_ID
OR
cbt -instance=INSTANCE_ID listclusters

To change the number of nodes:
gcloud bigtable clusters update CLUSTER_ID --instance=INSTANCE_ID --num-nodes=NUM_NODES
OR
cbt -instance=INSTANCE_ID updatecluster CLUSTER_ID NUM_NODES

To create a cluster using cbt command:
cbt -instance=INSTANCE_ID createcluster CLUSTER_ID ZONE NUM_NODES STORAGE_TYPE

To delete a cluster:
gcloud bigtable clusters delete CLUSTER_ID --instance=INSTANCE_ID
OR
cbt -instance=INSTANCE_ID deletecluster CLUSTER_ID

To create a table:
cbt createtable my-table

To list tables:
cbt ls

To create a column family named cf1:
cbt createfamily my-table cf1

To list column families:
cbt ls my-table

To put the value "test-value" in the row r1, using the column family cf1 and the column qualifier c1:
cbt set my-table r1 cf1:c1=test-value

To read the data in a table:
cbt read my-table

To delete the table:
cbt deletetable my-table
-------------------------------------------------------------------------------
LOGGING:

To read your Google Cloud project-level audit log entries:
gcloud logging read "logName : projects/PROJECT_ID/logs/cloudaudit.googleapis.com" --project=PROJECT_ID

To read your folder-level audit log entries:
gcloud logging read "logName : folders/FOLDER_ID/logs/cloudaudit.googleapis.com" --folder=FOLDER_ID

To read your organization-level audit log entries:
gcloud logging read "logName : organizations/ORGANIZATION_ID/logs/cloudaudit.googleapis.com" --organization=ORGANIZATION_ID

To create an aggregated sink for a folder:
gcloud logging sinks create SINK_NAME \
storage.googleapis.com/BUCKET_NAME --include-children \
--folder=FOLDER_ID --log-filter="logName:activity"
To create a sink on the organization level, replace --folder=[FOLDER_ID] with --organization=[ORGANIZATION_ID].
For a billing account, replace with --billing-account=[BILLING_ACCOUNT_ID].

To create a log sink (not aggregated):
To create a sink to a Cloud Logging log bucket
gcloud logging sinks create my-sink logging.googleapis.com/projects/myproject123/locations/global/buckets/my-bucket \
  --log-filter='logName="projects/myproject123/logs/matched"' --description="My first sink"
-------------------------------------------------------------------------------
APP engine:

To select a region and create an App Engine application:
gcloud app create --project=[YOUR_PROJECT_ID]
Each Cloud project can contain only a single App Engine application, and once created you cannot change the location of your App Engine application.

To check if an App Engine application exists in your Cloud project:
gcloud app describe

To retrieve the IDs of your app's services and versions:
gcloud app instances list

To list all services and versions:
gcloud app versions list

To list all versions for a specific service:
gcloud app versions list --service=service1

To list only versions that are receiving traffic:
gcloud app versions list --hide-no-traffic

To display all data about an existing version:
gcloud app versions describe [VERSION_ID] --service=default

To deploy the dispatch configuration file without otherwise altering the currently serving version:
gcloud app deploy dispatch.yaml
SEE: https://cloud.google.com/appengine/docs/standard/java11/how-requests-are-routed

To view the ingress setting for a service:
gcloud app services describe [SERVICE]

To update the ingress setting for a service:
gcloud app services update [SERVICE] --ingress=[INGRESS]
INGRESS: The ingress control you want to apply. One of all, internal-only, or internal-and-cloud-load-balancing.

To migrate traffic immediately:
gcloud app services set-traffic [MY_SERVICE] --splits [MY_VERSION]=1

To migrate traffic gradually:
gcloud app services set-traffic [MY_SERVICE] --splits [MY_VERSION]=1 --migrate

To split traffic between versions of a service:
gcloud app services set-traffic [MY_SERVICE] --splits [MY_VERSION1]=[VERSION1_WEIGHT],[MY_VERSION2]=[VERSION2_WEIGHT] --split-by [IP_OR_COOKIE]
For example:
To send all traffic to 'v2' of service 's1', run:
gcloud app services set-traffic s1 --splits=v2=1
To split traffic evenly between 'v1' and 'v2' of service 's1', run:
gcloud app services set-traffic s1 --splits=v2=.5,v1=.5
