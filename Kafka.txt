https://kafka.apache.org/quickstart/
https://www.youtube.com/watch?v=QkdkLdMBuL0
--------------------------------------------------------------------------------------
Kafka Partitions and Offsets:
https://www.youtube.com/watch?v=8L-1HSTf97E
--------------------------------------------------------------------------------------
https://www.youtube.com/watch?v=B5j3uNBH8X4
--------------------------------------------------------------------------------------
Partition replication:
In kafka, each partition can have multiple replicas(in distinct brokers) for fault tolerance. One replica is designated as the leader, and the others are followers. So when a producer sends data to a partition, it actually sends it to the leader replica. It's the job of the brokers with follower replicas to replicate the data from the leader.
When a broker that is a leader for a partition goes down, one of the followers is automatically promoted to be the new leader. This ensures that the partition remains available even in the event of broker failures. This is done automatically by Kafka's built-in replication mechanism.
--------------------------------------------------------------------------------------
Partition assignment (Auto generated by ChatGPT, need review):
When a consumer subscribes to a topic, Kafka assigns partitions to the consumer based on the consumer group. Each partition is assigned to only one consumer within a consumer group. If there are more consumers than partitions, some consumers will be idle. If there are more partitions than consumers, some consumers will be assigned multiple partitions.
Kafka uses a partition assignment strategy to determine how partitions are assigned to consumers. The default strategy is the range assignment strategy, which assigns partitions to consumers in a round-robin fashion. Other strategies include the round-robin assignment strategy and the sticky assignment strategy.
--------------------------------------------------------------------------------------
Kafka automatically manages partition assignments when consumers join or leave a consumer group. When a new consumer joins the group, Kafka reassigns partitions to ensure that all partitions are being consumed. When a consumer leaves the group, Kafka reassigns its partitions to the remaining consumers. This process is known as rebalancing.
--------------------------------------------------------------------------------------
Partitioning strategy:
There are several partitioning strategies in Kafka, including:
1. Round Robin: Messages are distributed evenly across all partitions in a round-robin fashion.
2. Key-based Partitioning: Messages with the same key are sent to the same partition. This is useful for maintaining order for messages with the same key. In this strategy, a hash function is applied on the key and then modulo operation with number of partitions is done to determine the partition number.
3. Custom Partitioning: You can implement your own partitioning logic by creating a custom partitioner class.
--------------------------------------------------------------------------------------
Consumer offsets:
In Kafka, each consumer keeps track of its position in each partition by maintaining an offset. The offset is a simple integer value that represents the position of the last consumed message in a partition. When a consumer reads messages from a partition, it updates its offset to reflect the position of the last consumed message. This allows the consumer to resume reading from where it left off in case of a failure or restart.
Apart from the consumer offset being stored in the consumer application memory, kafka also stores the offsets in a special topic called "consumer_offsets". This allows better fault tolerance, consistency and scalability in case of consumer group rebalancing.
--------------------------------------------------------------------------------------
Topic overall does not maintain a global order of messages. However, within a partition, messages are strictly ordered based on their offsets. This means that if a producer sends messages with the same key to a topic, those messages will be sent to the same partition and will be consumed in the order they were produced.
--------------------------------------------------------------------------------------
Data retention in Kafka (Auto generated by ChatGPT, need review):
Kafka retains messages for a configurable period of time, known as the retention period. The retention period can be set at the topic level using the "retention.ms" configuration property. Once the retention period has elapsed, Kafka will automatically delete the messages from the topic.
In addition to time-based retention, Kafka also supports size-based retention. This can be configured using the "retention.bytes" property. When the size of the topic exceeds the configured limit, Kafka will delete the oldest messages to make room for new messages.
Message deletion happpens segment-wise. So when the newest message in a segment exceeds the retention period or size limit, the entire segment is deleted.
The default retention period in Kafka is 7 days, but it can be adjusted based on the use case and requirements.
--------------------------------------------------------------------------------------
Producer acknowledgments:
In Kafka, producer acknowledgments (acks) determine the level of guarantee that a message has been successfully written to the Kafka cluster. There are three levels of acknowledgments that a producer can request:
1. acks=0: The producer does not wait for any acknowledgment from the broker. This means that the producer will consider the message as sent as soon as it is written to the network buffer. This provides the lowest latency but also the lowest guarantee of message delivery.
2. acks=1: The producer waits for an acknowledgment from the leader broker of the partition to which the message was sent. This means that the producer will consider the message as sent once the leader broker has written the message to its local log. This provides a balance between latency and message delivery guarantee.
3. acks=all (or acks=-1): The producer waits for acknowledgments from all in-sync replicas (ISRs) of the partition to which the message was sent. This means that the producer will consider the message as sent only when all replicas have written the message to their local logs. This provides the highest guarantee of message delivery but also the highest latency.
The choice of acknowledgment level depends on the specific use case and requirements for message delivery guarantees and latency.
--------------------------------------------------------------------------------------
Delivery semantics in Kafka:
1. At-most-once: Messages may be lost but are never redelivered. This can occur when the producer sends a message and does not wait for an acknowledgment (acks=0). If the message is lost in transit or the broker fails before it can be written to the log, the message will not be delivered to the consumer.
2. At-least-once: Messages are never lost but may be redelivered. This can occur when the producer waits for an acknowledgment from the broker (acks=1 or acks=all). If the producer does not receive an acknowledgment, it may retry sending the message, resulting in duplicate messages being delivered to the consumer.
3. Exactly-once: Each message is delivered exactly once to the consumer. This is achieved through a combination of idempotent producers and transactional messaging. Idempotent producers ensure that duplicate messages are not written to the log, while transactional messaging allows a group of messages to be sent atomically.
--------------------------------------------------------------------------------------
Idempotent producers in Kafka:
Idempotent producers in Kafka ensure that duplicate messages are not written to the log, even if the producer retries sending a message due to a failure or timeout. This is achieved by assigning a unique sequence number to each message sent by the producer. The broker uses this sequence number to detect and discard duplicate messages.
To enable idempotent producers, the producer must set the "enable.idempotence" configuration property to true. When this property is set, the producer will automatically assign sequence numbers to messages and handle retries in a way that ensures idempotency.
Idempotent producers are particularly useful in scenarios where the producer may experience transient failures or timeouts, as they help to prevent duplicate messages from being written to the log.
Check archived chatgpt "idempotent producers in kafka"
--------------------------------------------------------------------------------------